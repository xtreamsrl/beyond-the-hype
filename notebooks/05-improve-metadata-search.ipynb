{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Leverage Metadata to Improve Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Until now, our RAG has only leveraged similarity between user questions and movie plots, with or without HyDE. **Our dataset is richer than just the plot column.** What about the release date or genre columns? Could this information help us improve our movie expertise? \n",
    "\n",
    "It turns out that our RAG could better reply to some questions. How our system deals with questions like: \n",
    "- Could you suggest a romantic movie from the '90s\n",
    "- I love action movies, could you suggest one? \n",
    "\n",
    "Let's see what we can do to improve our \"movies buddy\" a step further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install some code utilities\n",
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec(\"beyond_the_hype\"):\n",
    "    !pip install -qqq git+https://github.com/xtreamsrl/beyond-the-hype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Let's Play with LanceDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "import openai\n",
    "import polars as pl\n",
    "from pydantic import BaseModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from beyond_the_hype.data import get_movies_dataset\n",
    "from beyond_the_hype.judge import answer_multiple_questions, llm_as_a_judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "movies = get_movies_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"./movies_embeddings\"\n",
    "db = lancedb.connect(uri)\n",
    "\n",
    "movies_table = db.create_table(\"movies\", movies, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Let's see what movies are retrieved from database just using semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"I love '90 fantasy movies with dragons\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_table.search(encoder.encode(question)).limit(10).select(\n",
    "    [\"title\", \"release_year\", \"genre\"]\n",
    ").to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "The retrieved movies looks good, they are all aventure or fantasy movies with some relation with dragosn as asked by the user. **The problem is that many of them are not from 90s!** This is due the fact that the semantic search using enbeddings doesn't taken into account the movies release year.\n",
    "\n",
    "Fortunatelly, many vector database have a useful filtering query system. LanceDB, for example, support filtering data using a SQL-like language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_table.search(encoder.encode(question)).where(\n",
    "    \"genre LIKE '%fantasy%' AND (release_year >= 1990 AND release_year < 2000)\"\n",
    ").select([\"title\", \"release_year\", \"genre\"]).limit(10).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Hurray! Looks better, all movies now are from 90s. Now the metadata informations in the questions are useless we could just search for \"dragons\" and see what happen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_table.search(encoder.encode(\"dragons\")).where(\n",
    "    \"genre LIKE '%fantasy%' AND (release_year >= 1990 AND release_year < 2000)\"\n",
    ").select([\"title\", \"release_year\", \"genre\"]).limit(10).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Even better! So, based on this experiments we need something to convert the natural language user query to a SQL-like filter (or other languages supported by your vector database). \n",
    "\n",
    "To do this LLM could help us. We can ask a model to do this job for us and adding a step to our RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## ðŸ‹ðŸ» Exercise: Play With LanceDB Filters!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Before exploring how we can generate filters and questions given a natural language question using LLM, **it is crucial to understand how search works**. \n",
    "\n",
    "Take some time to play with lanceDB filters, dig into [documentation](https://lancedb.github.io/lancedb/sql/), and try to find some edge cases or database limitations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_METADATA_SYS_MESSAGE = \"\"\"Your goal is to structure the user's query to match the request schema provided below.\n",
    "When responding, use a data structure with the following schema:\n",
    "\n",
    "query (string): text string to compare to document contents\n",
    "filter: (string): logical condition statement for filtering documents\n",
    "\n",
    "You need to build filters for a database with the following fields: \n",
    "\n",
    "{fields}\n",
    "\n",
    "The query string should contain only text expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query.\n",
    "You can use standard SQL expressions as predicates for filtering operations. You can use the following list of SQL expressions:\n",
    "\n",
    "{supported_operations}\n",
    "\n",
    "For genre, director, cast, and origin, use always LIKE with % wildcard at the begin. For example origin LIKE '%British%'\n",
    "\n",
    "Make sure you only use the comparators and logical operators listed above and not others.\n",
    "Make sure that filters only refer to attributes in the data source.\n",
    "Make sure that filters only use the attributed names with their function names if there are functions applied to them.\n",
    "Make sure that filters only use the format `YYYY` when handling years.\n",
    "Make sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\n",
    "Make sure that filters are only used as needed. If no filters should be applied, return \"NO_FILTER\" for the filter value.\n",
    "\n",
    "<< Example 1. >>\n",
    "User Query:\n",
    "I love action American movies with superheroes\n",
    "\n",
    "Structured Request:\n",
    "\"query\": \"Superheroes\",\n",
    "\"filter\": \"genre LIKE '%action%' AND origin = 'American'\"\n",
    "\n",
    "<< Example 2. >>\n",
    "User Query:\n",
    "I love '90 fantasy movies with dragons\n",
    "\n",
    "Structured Request:\n",
    "\"query\": \"Dragons\",\n",
    "\"filter\": \"genre LIKE '%fantasy%' AND (release_year >= 1990 AND release_year < 2000)\"\n",
    "\"\"\"\n",
    "\n",
    "supported_operations = [\n",
    "    \">, >=, <, <=, =\",\n",
    "    \"AND, OR, NOT\",\n",
    "    \"IS NULL, IS NOT NULL\",\n",
    "    \"IS TRUE, IS NOT TRUE, IS FALSE, IS NOT FALSE\",\n",
    "    \"IN\",\n",
    "    \"LIKE, NOT LIKE\",\n",
    "    \"CAST\",\n",
    "    \"regexp_match(column, pattern)\",\n",
    "]\n",
    "\n",
    "\n",
    "formatted_supported_operations = \"\\n\".join(supported_operations)\n",
    "query_metadata_system_message = QUERY_METADATA_SYS_MESSAGE.format(\n",
    "    fields=movies_table.schema, supported_operations=formatted_supported_operations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_metadata_system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDBQuery(BaseModel):\n",
    "    query: str\n",
    "    filter: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectordb_query_builder(\n",
    "    user_question: str,\n",
    "    system_message: str = query_metadata_system_message,\n",
    "):\n",
    "    client = openai.OpenAI()\n",
    "    prompt = f\"Could you generate query and filter for the following user natural language question: {user_question}\"\n",
    "\n",
    "    chat_completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        response_format=VectorDBQuery,\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_records(\n",
    "    query: VectorDBQuery,\n",
    "    *,\n",
    "    encoder=encoder,\n",
    "    db_table=movies_table,\n",
    "    max_results=10,\n",
    "    verbose=False,\n",
    "):\n",
    "    query_vector = encoder.encode(query.query).tolist()\n",
    "    columns = [\n",
    "        \"release_year\",\n",
    "        \"title\",\n",
    "        \"origin\",\n",
    "        \"director\",\n",
    "        \"cast\",\n",
    "        \"genre\",\n",
    "        \"plot\",\n",
    "        \"_distance\",\n",
    "    ]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Query: {query.query}\")\n",
    "        print(f\"Filter: {query.filter}\")\n",
    "\n",
    "    if query.filter == \"NO_FILTER\":\n",
    "        return (\n",
    "            db_table.search(query_vector).limit(max_results).select(columns).to_list()\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            db_table.search(query_vector)\n",
    "            .where(query.filter)\n",
    "            .limit(max_results)\n",
    "            .select(columns)\n",
    "            .to_list()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Now that we have improve the `get_records` methods taking into consideration also metadata. We could build the rag again! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"\"\"You are a movie expert whose goal is to recommend a good movie to the user.\n",
    "\n",
    "RULES: \n",
    "- You should reply to questions about movie plots or Synopsys, movies metadata (release date, cast, or director), and provide plot summary;\n",
    "- For every question outside the scope, please reply politely that you're not able to provide a response and describe briefly your scope;\n",
    "- Don't mention that you have a list of films as a context. This should be transparent to the user\n",
    "- If you don't have the movie in your context, reply that you don't know how to reply\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "  Here are some suggested movies (ranked by relevance) to help you with your choice.\n",
    "  {context}\n",
    "\n",
    "  Use these suggestions to answer this question:\n",
    "  {question}\n",
    "\"\"\"\n",
    "\n",
    "context_template = \"\"\"\n",
    "Title: {title}\n",
    "Release date: {release_year}\n",
    "Director: {director}\n",
    "Cast: {cast}\n",
    "Genre: {genre}\n",
    "Overview: {plot}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def format_records_into_context(records, *, template):\n",
    "    return \"\".join(\n",
    "        context_template.format(\n",
    "            title=rec[\"title\"],\n",
    "            release_year=rec[\"release_year\"],\n",
    "            director=rec[\"director\"],\n",
    "            cast=rec[\"cast\"],\n",
    "            genre=rec[\"genre\"],\n",
    "            plot=rec[\"plot\"],\n",
    "        )\n",
    "        for rec in records\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "\n",
    "\n",
    "def ask(\n",
    "    question,\n",
    "    *,\n",
    "    max_results=10,\n",
    "    system=SYSTEM_MESSAGE,\n",
    "    prompt_template=prompt_template,\n",
    "    context_template=context_template,\n",
    "    db_table=movies_table,\n",
    "    verbose=False,\n",
    "):\n",
    "    db_query = vectordb_query_builder(question)\n",
    "    records = get_records(\n",
    "        query=db_query, max_results=max_results, db_table=movies_table, verbose=verbose\n",
    "    )\n",
    "\n",
    "    context = format_records_into_context(records, template=context_template)\n",
    "\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    answer = chat_completion\n",
    "    if verbose:\n",
    "        print(answer.choices[0].message.content)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"I love '90 fantasy movies with dragons\"\n",
    "answer = ask(question=question, verbose=True)\n",
    "print()\n",
    "print(answer.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many Rocky movies where filmed?\"\n",
    "answer = ask(question=question, verbose=True)\n",
    "print()\n",
    "print(answer.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = (\n",
    "    \"I love Turkish movies, and my preferred director is Ã–zpetek! What movie can I see?\"\n",
    ")\n",
    "answer = ask(question=question, verbose=True)\n",
    "print(answer.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# But... Is Our RAG Improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Let's take our questions/answers dataset and run again our LLM-as-a-Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_answers_df = pl.read_csv(\"eval_replies.csv\").select(\"question\", \"rag_answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "replied_answers = answer_multiple_questions(questions_answers_df, ask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "judged_questions_answer_df = llm_as_a_judge(questions_answers_df, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "judged_questions_answer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "## ðŸ‹ðŸ» Exercise: Improve Query Generator Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "The system could not be replying perfectly yet. Have a look again on query generation system message, iterate over it adding some rules or examples and try to fix many bugs as possible. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
